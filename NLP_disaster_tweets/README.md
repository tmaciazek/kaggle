# kaggle
My kaggle projects.

## Titanic

This is the [Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic) competition.

Afted data cleaning ([titanic_data_cleaning.ipynb](https://github.com/tmaciazek/kaggle/blob/main/titanic/titanic_data_cleaning.ipynb)), I approach this using three techniques:

-  logistic regression using polynomial features (of order $2$) combined with PCA ([logistic.ipynb](https://github.com/tmaciazek/kaggle/blob/main/titanic/logistic.ipynb)),
-  a single decision tree ([tree.ipynb](https://github.com/tmaciazek/kaggle/blob/main/titanic/tree.ipynb)),
-  a random forest ([random_forest.ipynb](https://github.com/tmaciazek/kaggle/blob/main/titanic/random_forest.ipynb)).
