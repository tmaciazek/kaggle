{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9aefa8a",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Disaster Tweets - Bidirectional LSTM Recurrent Neural Net\n",
    "\n",
    "In this notebook, we will make predictions about the disaster tweets using a recurrent neural net with two Bidirectional LSTM layers.\n",
    "\n",
    "We will be using Tensorflow's functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76c6d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# suppress warnings\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, Concatenate\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf7675d",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "We rely on GloVe word embeddings. The specific data we use is [glove.twitter.27B](https://nlp.stanford.edu/projects/glove/). The following function reads the GloVe data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0792ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove(glove_file):\n",
    "    \"\"\"\n",
    "    glove_file - path to the glove file\n",
    "    \n",
    "    returns:\n",
    "    words_to_index - dictionary matching word (string) to its index in the sorted glove dataset\n",
    "    word_to_vec - like above, but returns the corresponding embedding vector\n",
    "    \"\"\"\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        for w in sorted(words): # sorting!\n",
    "            words_to_index[w] = i\n",
    "            i = i + 1\n",
    "    return words_to_index, word_to_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "910a830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the dimension of word embeddings: 25, 50, 100, 200\n",
    "emb_dim = 100\n",
    "word_to_index, word_to_vec = read_glove(\n",
    "    'data/glove.twitter.27B/glove.twitter.27B.'+str(emb_dim)+'d.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c005a127",
   "metadata": {},
   "source": [
    "Next, we read the previously cleaned location data as well as the tokenized tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abffb9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_locations(loc_file):\n",
    "    \"\"\"\n",
    "    loc_file - path to the csv file containing locations\n",
    "    returns vector of the shape (n_locations, 1) of strings which are the locations\n",
    "    \"\"\"\n",
    "    locations = pd.read_csv(loc_file)\n",
    "    locations = locations.fillna('Worldwide')\n",
    "    \n",
    "    return locations['location'].values.reshape((locations.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ece0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xloc_train = read_locations('data/location_train.csv')\n",
    "Xloc_test = read_locations('data/location_test.csv')\n",
    "Xloc_alldata = np.concatenate([Xloc_train, Xloc_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ecbfd7",
   "metadata": {},
   "source": [
    "One-hot encode the locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "482f23a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique locations:\t154\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(Xloc_alldata)\n",
    "\n",
    "Xloc_train_one_hot = enc.transform(Xloc_train).toarray()\n",
    "Xloc_test_one_hot = enc.transform(Xloc_test).toarray()\n",
    "\n",
    "loc_one_hot_length = Xloc_test_one_hot.shape[1]\n",
    "print( \"Number of unique locations:\\t\" + str(loc_one_hot_length) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb7746c",
   "metadata": {},
   "source": [
    "Next, we read the tweet indices that we created in the notebook [tweets_preprocessing.ipynb](tweets_preprocessing.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bcf6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tweet_indices(ind_file):\n",
    "    \"\"\"\n",
    "    ind_file - path to the file containing indices separated by spaces (tweets in consecutive lines)\n",
    "    \n",
    "    returns:\n",
    "    lines - list of lists of indices (as strings)\n",
    "    maxLen - maximum length of a tweet\n",
    "    \"\"\"\n",
    "    with open(ind_file, 'r') as f:\n",
    "        lines=[]\n",
    "        maxLen=0\n",
    "        for line in f:\n",
    "            lines.append( line.strip().split() )\n",
    "            if len(lines[-1]) > maxLen: maxLen=len(lines[-1])\n",
    "        return lines, maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f3bf25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_Xtxt(ind_file_train, ind_file_test):\n",
    "    \"\"\"\n",
    "    ind_file_train - path to the train file containing indices of tweets\n",
    "    ind_file_test - path to the test file containing indices of tweets\n",
    "    \n",
    "    returns:\n",
    "    maxLen - maximum length of a tweet\n",
    "    X_train, X_test - matrices of indices of words in tweets filled with zeros - dimensions (N_tweets, maxLen) \n",
    "    \"\"\"\n",
    "    lines_test, maxLen_test = read_tweet_indices(ind_file_test)\n",
    "    lines_train, maxLen_train = read_tweet_indices(ind_file_train)\n",
    "    \n",
    "    maxLen = max(maxLen_test, maxLen_train)\n",
    "    \n",
    "    X_test=np.zeros((len(lines_test), maxLen), dtype=int)\n",
    "    X_train=np.zeros((len(lines_train), maxLen), dtype=int)\n",
    "    for i in range(len(lines_test)):\n",
    "        for j in range(len(lines_test[i])):\n",
    "            X_test[i,j] = int(lines_test[i][j])\n",
    "    \n",
    "    for i in range(len(lines_train)):\n",
    "        for j in range(len(lines_train[i])):\n",
    "            X_train[i,j] = int(lines_train[i][j])\n",
    "    \n",
    "    return X_train, X_test, maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69bc41f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum tweet length:\t38\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, maxLen = construct_Xtxt('data/tweet_indices_train.txt', 'data/tweet_indices_test.txt')\n",
    "print( \"Maximum tweet length:\\t\" + str(maxLen) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66539afa",
   "metadata": {},
   "source": [
    "Finally, we read off the target vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b8171cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = pd.read_csv('data/train.csv')['target']\n",
    "Y_train = Y_train.to_numpy().reshape(Y_train.shape[0],-1).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07406590",
   "metadata": {},
   "source": [
    "## The LSTM Recurrent Neural Net\n",
    "\n",
    "First, we define the embedding layer which takes the index matrix as input and returns the embeddings - output shape `(N_tweets, maxLen, emb_dim)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fed3a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec, word_to_index):\n",
    "    \"\"\"\n",
    "    Creates Embedding() layer and loads in pre-trained GloVe vectors.\n",
    "    \n",
    "    Arguments:\n",
    "    word_to_vec -- dictionary mapping words to their GloVe vector representation.\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer \n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    any_word = list(word_to_vec.keys())[0]\n",
    "    emb_dim = word_to_vec[any_word].shape[0] # dimension of the GloVe word vectors\n",
    "      \n",
    "    # Initialize the embedding matrix as a numpy array of zeros.\n",
    "    emb_matrix = np.zeros((vocab_size, emb_dim))\n",
    "    \n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        word_vec = word_to_vec[word]\n",
    "        if word_vec.shape[0] == emb_dim:\n",
    "            emb_matrix[idx, :] = word_vec\n",
    "\n",
    "    # Define embedding layer and make it non-trainable.\n",
    "    embedding_layer = Embedding(vocab_size, emb_dim, trainable=False) \n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6b2168",
   "metadata": {},
   "source": [
    "Next, we construct the RNN according to the schamtic picture below.\n",
    "<img src=\"net.png\" width=\"620\" height=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55178622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_tweets(input_indices_shape, input_loc_shape, word_to_vec, word_to_index):\n",
    "    \"\"\"\n",
    "    Function creating the NLP model graph.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the input (max_len,)\n",
    "    word_to_vec -- dictionary mapping every word in a vocabulary into its vector representation\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define sentence_indices as input1 of the graph.\n",
    "    sentence_indices = Input(shape=input_indices_shape, dtype=tf.int32)\n",
    "    \n",
    "    # Define Xloc_one_hot as input2 of the graph\n",
    "    Xloc_one_hot = Input(shape=input_loc_shape, dtype=tf.float32)\n",
    "    \n",
    "    # Create the embedding layer pretrained with GloVe Vectors\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec, word_to_index)\n",
    "    \n",
    "    # Propagate sentence_indices through your embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    \n",
    "    # Propagate the embeddings through an LSTM layer, return sequences.\n",
    "    X = Bidirectional(LSTM(units=128, return_sequences=True, recurrent_dropout=0.3))(embeddings)\n",
    "    # Add dropout\n",
    "    X = Dropout(rate=0.7)(X)\n",
    "    # Propagate X trough another LSTM layer, return a single hidden state.\n",
    "    X = Bidirectional(LSTM(units=128, return_sequences=False, recurrent_dropout=0.3))(X)\n",
    "    # Add dropout\n",
    "    X = Dropout(rate=0.7)(X) \n",
    "    # Concatenate X with Xloc_one_hot\n",
    "    X = Concatenate()([X, Xloc_one_hot])\n",
    "    # Propagate X through a Dense layer\n",
    "    X = Dense(units=100, activation='ReLU')(X)\n",
    "    # Add dropout\n",
    "    X = Dropout(rate=0.2)(X)\n",
    "    # Output\n",
    "    X = Dense(units=1, activation='sigmoid')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs=[sentence_indices, Xloc_one_hot], outputs=X, name='NLP_Twitter')\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3b97376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"NLP_Twitter\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 38)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 38, 100)              1193515   ['input_1[0][0]']             \n",
      "                                                          00                                      \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 38, 256)              234496    ['embedding[0][0]']           \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 38, 256)              0         ['bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, 256)                  394240    ['dropout[0][0]']             \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 256)                  0         ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 154)]                0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 410)                  0         ['dropout_1[0][0]',           \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 100)                  41100     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 100)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    101       ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 120021437 (457.85 MB)\n",
      "Trainable params: 669937 (2.56 MB)\n",
      "Non-trainable params: 119351500 (455.29 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = nlp_tweets((maxLen,), (loc_one_hot_length, ), word_to_vec, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df147866",
   "metadata": {},
   "source": [
    "According to the competition info, the evaluation metric is F1 score. Below, we implement this metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2e5fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d1e098",
   "metadata": {},
   "source": [
    "Next, we compile the model with F1 score metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea0cc1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam()\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[f1_m])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b7d49d",
   "metadata": {},
   "source": [
    "We split the train set into train and dev sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4906bb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate([X_train, Xloc_train_one_hot], axis=1)\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(X_train, Y_train, test_size=0.2, random_state=42, shuffle=True, stratify=Y_train)\n",
    "\n",
    "# extract text and location parts\n",
    "Xloc_train = np.copy( X_train[:, -loc_one_hot_length:] )\n",
    "Xtxt_train = np.copy( X_train[:, :maxLen] )\n",
    "Xloc_dev = np.copy( X_dev[:, -loc_one_hot_length:] )\n",
    "Xtxt_dev = np.copy( X_dev[:, :maxLen] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7100d40c",
   "metadata": {},
   "source": [
    "It's time to train the model! We will train it with learinng rate $0.0001$ for the first 25 epochs and then decrease it to $0.00001$. We also implement early stopping via `tf.keras.callbacks.ReduceLROnPlateau` and `tf.keras.callbacks.EarlyStopping`. It will prevent overfitting. If you train the model for any longer, you will see that the CV score will start to slowly drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47a81f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 25:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.00001\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=3, verbose=1),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7),\n",
    "    tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ee707e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "96/96 [==============================] - 29s 229ms/step - loss: 0.6547 - f1_m: 0.4553 - val_loss: 0.5497 - val_f1_m: 0.6955 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 22s 225ms/step - loss: 0.4975 - f1_m: 0.7167 - val_loss: 0.4454 - val_f1_m: 0.7440 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 21s 224ms/step - loss: 0.4505 - f1_m: 0.7526 - val_loss: 0.4336 - val_f1_m: 0.7763 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 23s 245ms/step - loss: 0.4406 - f1_m: 0.7520 - val_loss: 0.4428 - val_f1_m: 0.7807 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 27s 280ms/step - loss: 0.4363 - f1_m: 0.7533 - val_loss: 0.4300 - val_f1_m: 0.7821 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 21s 220ms/step - loss: 0.4262 - f1_m: 0.7659 - val_loss: 0.4274 - val_f1_m: 0.7710 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 22s 234ms/step - loss: 0.4275 - f1_m: 0.7628 - val_loss: 0.4228 - val_f1_m: 0.7769 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 20s 203ms/step - loss: 0.4224 - f1_m: 0.7636 - val_loss: 0.4260 - val_f1_m: 0.7847 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.4198 - f1_m: 0.7731 - val_loss: 0.4280 - val_f1_m: 0.7821 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 19s 202ms/step - loss: 0.4144 - f1_m: 0.7799 - val_loss: 0.4218 - val_f1_m: 0.7810 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 19s 203ms/step - loss: 0.4137 - f1_m: 0.7636 - val_loss: 0.4219 - val_f1_m: 0.7817 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 20s 213ms/step - loss: 0.4109 - f1_m: 0.7772 - val_loss: 0.4217 - val_f1_m: 0.7771 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 18s 191ms/step - loss: 0.4043 - f1_m: 0.7715 - val_loss: 0.4234 - val_f1_m: 0.7834 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.4044 - f1_m: 0.7816 - val_loss: 0.4265 - val_f1_m: 0.7883 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 23s 237ms/step - loss: 0.4025 - f1_m: 0.7842 - val_loss: 0.4323 - val_f1_m: 0.7825 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 23s 242ms/step - loss: 0.3999 - f1_m: 0.7778 - val_loss: 0.4221 - val_f1_m: 0.7800 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 20s 210ms/step - loss: 0.3978 - f1_m: 0.7887 - val_loss: 0.4354 - val_f1_m: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 20s 205ms/step - loss: 0.3961 - f1_m: 0.7800 - val_loss: 0.4306 - val_f1_m: 0.7904 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.3966 - f1_m: 0.7868 - val_loss: 0.4259 - val_f1_m: 0.7825 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 19s 198ms/step - loss: 0.3876 - f1_m: 0.7879 - val_loss: 0.4314 - val_f1_m: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 19s 200ms/step - loss: 0.3835 - f1_m: 0.7941 - val_loss: 0.4190 - val_f1_m: 0.7745 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 21s 217ms/step - loss: 0.3843 - f1_m: 0.7897 - val_loss: 0.4245 - val_f1_m: 0.7792 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 19s 199ms/step - loss: 0.3772 - f1_m: 0.7908 - val_loss: 0.4196 - val_f1_m: 0.7854 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 18s 185ms/step - loss: 0.3776 - f1_m: 0.7934 - val_loss: 0.4220 - val_f1_m: 0.7830 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 18s 190ms/step - loss: 0.3766 - f1_m: 0.7930 - val_loss: 0.4200 - val_f1_m: 0.7746 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 19s 202ms/step - loss: 0.3691 - f1_m: 0.7911 - val_loss: 0.4223 - val_f1_m: 0.7891 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 18s 186ms/step - loss: 0.3594 - f1_m: 0.8072 - val_loss: 0.4226 - val_f1_m: 0.7823 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 18s 185ms/step - loss: 0.3596 - f1_m: 0.8076 - val_loss: 0.4307 - val_f1_m: 0.7902 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 18s 190ms/step - loss: 0.3593 - f1_m: 0.8046 - val_loss: 0.4253 - val_f1_m: 0.7865 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.3617 - f1_m: 0.8036\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "96/96 [==============================] - 19s 199ms/step - loss: 0.3617 - f1_m: 0.8036 - val_loss: 0.4269 - val_f1_m: 0.7861 - lr: 1.0000e-06\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 21s 215ms/step - loss: 0.3585 - f1_m: 0.8120 - val_loss: 0.4301 - val_f1_m: 0.7893 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 21s 224ms/step - loss: 0.3564 - f1_m: 0.8084 - val_loss: 0.4281 - val_f1_m: 0.7833 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 20s 208ms/step - loss: 0.3594 - f1_m: 0.8085 - val_loss: 0.4322 - val_f1_m: 0.7895 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "96/96 [==============================] - 20s 208ms/step - loss: 0.3552 - f1_m: 0.8155 - val_loss: 0.4299 - val_f1_m: 0.7867 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "96/96 [==============================] - 20s 206ms/step - loss: 0.3566 - f1_m: 0.8062 - val_loss: 0.4297 - val_f1_m: 0.7878 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "96/96 [==============================] - 19s 198ms/step - loss: 0.3558 - f1_m: 0.8070 - val_loss: 0.4307 - val_f1_m: 0.7881 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "60/96 [=================>............] - ETA: 6s - loss: 0.3525 - f1_m: 0.8106"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [Xtxt_train, Xloc_train], Y_train, validation_data = (\n",
    "        [Xtxt_dev, Xloc_dev], Y_dev\n",
    "    ) , epochs = 100, batch_size = 64, shuffle=True, callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8af21e2",
   "metadata": {},
   "source": [
    "Plot the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c526210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "axs[0].set_title('Loss')\n",
    "axs[0].plot(history.history['loss'], label='train')\n",
    "axs[0].plot(history.history['val_loss'], label='val')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_title('F1 score')\n",
    "axs[1].plot(history.history['f1_m'], label='train')\n",
    "axs[1].plot(history.history['val_f1_m'], label='val')\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03874bbb",
   "metadata": {},
   "source": [
    "Generate the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098184c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=( model.predict([ X_test, Xloc_test_one_hot]) > 0.5 ).astype(int)\n",
    "submission = pd.read_csv( 'data/test.csv' )[['id']]\n",
    "submission['target'] = y_pred\n",
    "print(submission.head(10))\n",
    "submission.to_csv('submission_RNN_earlystop.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8e374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
